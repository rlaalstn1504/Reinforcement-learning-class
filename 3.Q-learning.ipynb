{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwTSusBLbqfrsHajJGkJ0v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Q-Learning"],"metadata":{"id":"84kFfRvmJAeE"}},{"cell_type":"markdown","source":["Q-Learningì€ ê°•í™”í•™ìŠµì˜ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ë¡œ, í™˜ê²½ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìµœì ì˜ ì •ì±…ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n","\n","<img src=\"https://www.researchgate.net/profile/Silvia-Ullo/publication/351884746/figure/fig1/AS:1067993664589824@1631640940747/Q-Learning-vs-Deep-Q-Learning.ppm\" width=\"600\">\n","\n","[ì´ë¯¸ì§€ ì¶œì²˜] https://www.researchgate.net/figure/Q-Learning-vs-Deep-Q-Learning_fig1_351884746\n","\n","## í•µì‹¬ ê°œë…\n","\n","- **Q-í•¨ìˆ˜**: ìƒíƒœ-í–‰ë™ ê°€ì¹˜ í•¨ìˆ˜ë¼ê³ ë„ ë¶ˆë¦¬ë©° ìƒíƒœ(s)ì—ì„œ í–‰ë™(a)ì„ ì·¨í–ˆì„ ë•Œì˜ ì˜ˆìƒ ê°€ì¹˜ë¥¼ ë¦¬í„´í•˜ëŠ”  í•¨ìˆ˜. ë²¨ë§Œ ë°©ì •ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ Qê°’ì„ ê°±ì‹ í•¨\n","- **ë²¨ë§Œ ë°©ì •ì‹**: Q(s,a) = r + Î³ * max(Q(s',a'))\n","  - Q($s_t$,$a_t$) : í˜„ì¬ ìƒíƒœ $s_t$ì—ì„œ í–‰ë™$a_t$ë¥¼ í–ˆì„ ë•Œ ê¸°ëŒ€ë˜ëŠ” ëˆ„ì  ë³´ìƒ\n","  - r: ì¦‰ê°ì ì¸ ë³´ìƒ\n","  - Î³: í• ì¸ ê³„ìˆ˜\n","  - s': ë‹¤ìŒ ìƒíƒœ\n","  - a': ë‹¤ìŒ ìƒíƒœì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  í–‰ë™\n","- **Q-í•¨ìˆ˜ ì—…ë°ì´íŠ¸ ì‹**:\n","  - $$\n","  Q(s_t, a_t) \\leftarrow (1-\\alpha)Q(s_t, a_t) + \\alpha \\big(r + \\gamma \\max_{a'} Q(s_{t+1}, a') - Q(s_t, a_t)\\big)\n","  $$\n","  - $\\alpha$: í•™ìŠµë¥  (0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ, ìƒˆë¡œìš´ ì •ë³´ì˜ ë°˜ì˜ ì •ë„ë¥¼ ì¡°ì ˆ)\n","  - ì—…ë°ì´íŠ¸ëŠ” í˜„ì¬ $Q(s_t, a_t)$ ê°’ì„ ë³´ìƒê³¼ ë‹¤ìŒ ìƒíƒœì˜ ìµœëŒ“ê°’ì„ ë°˜ì˜í•˜ì—¬ ì¡°ê¸ˆì”© ê°œì„ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n","\n","- **Îµ-greedy ì •ì±…**: íƒí—˜(exploration)ê³¼ í™œìš©(exploitation)ì˜ ê· í˜•ì„ ìœ„í•œ ì •ì±…\n","  - Exploration (íƒí—˜): ì•„ì§ ì‹œë„í•´ë³´ì§€ ì•Šì€ í–‰ë™ì„ ì„ íƒí•˜ì—¬ ë” ë‚˜ì€ ë³´ìƒì„ ì°¾ëŠ” ê³¼ì •.ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆì§€ë§Œ, ë‹¨ê¸°ì ìœ¼ë¡œëŠ” ë³´ìƒì´ ë‚®ì„ ìˆ˜ ìˆìŒ.\n","\n","  - Exploitation (í™œìš©): ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´ì—ì„œ ê°€ì¥ ë†’ì€ ë³´ìƒì„ ì¤„ ê²ƒì´ë¼ê³  ì˜ˆìƒë˜ëŠ” í–‰ë™ì„ ì„ íƒ. í˜„ì¬ì˜ ì§€ì‹ìœ¼ë¡œ ìµœëŒ€ ë³´ìƒì„ ì–»ìœ¼ë ¤ëŠ” ì ‘ê·¼. Îµ-Greedy ì •ì±…ì€ ì´ ë‘ ê³¼ì •ì„ ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ í˜¼í•©í•©ë‹ˆë‹¤:\n","  \n","  - í™•ë¥  Îµë¡œ ëœë¤í•˜ê²Œ í–‰ë™ì„ ì„ íƒ(íƒí—˜).**í™•ë¥  (1âˆ’ğœ€)**ë¡œ í˜„ì¬ ê°€ì¥ ë†’ì€ ë³´ìƒì„ ì¤„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” í–‰ë™ ì„ íƒ(í™œìš©)\n","\n","\n","\n","## ì•Œê³ ë¦¬ì¦˜ ë‹¨ê³„\n","\n","1. Q-í…Œì´ë¸” ì´ˆê¸°í™”\n","2. í˜„ì¬ ìƒíƒœ ê´€ì°°\n","3. Îµ-greedy ì •ì±…ì— ë”°ë¼ í–‰ë™ ì„ íƒ\n","4. í–‰ë™ ìˆ˜í–‰ ë° ë³´ìƒ íšë“\n","5. Q-í•¨ìˆ˜ ì—…ë°ì´íŠ¸\n","6. ìƒˆë¡œìš´ ìƒíƒœë¡œ ì´ë™\n","7. 2-6 ë‹¨ê³„ ë°˜ë³µ\n","\n","## ì¥ë‹¨ì \n","\n","### ì¥ì :\n","- ëª¨ë¸ ì—†ì´ í•™ìŠµ ê°€ëŠ¥ (ëª¨ë¸ í”„ë¦¬ ì ‘ê·¼ë²•)\n","- í•™ìŠµ ì¢…ë£Œ ì‹œ ìˆ˜ë ´ì„± ë³´ì¥\n","\n","### ë‹¨ì :\n","- í° ìƒíƒœ ê³µê°„ì—ì„œëŠ” ë¹„íš¨ìœ¨ì \n","- ì—°ì†ì ì¸ ìƒíƒœë‚˜ í–‰ë™ ì²˜ë¦¬ì— ì œí•œ\n","  - 1. ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ì¦ê°€ : í° ìƒíƒœ ê³µê°„ì—ì„œëŠ” Q-í…Œì´ë¸”ì˜ í¬ê¸°ê°€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤. ê° ìƒíƒœ-í–‰ë™ ìŒì— ëŒ€í•œ Q-ê°’ì„ ì €ì¥í•´ì•¼ í•˜ë¯€ë¡œ, ìƒíƒœì˜ ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ê¸‰ê²©íˆ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n","  - 2. í•™ìŠµ ì‹œê°„ ì¦ê°€ : ìƒíƒœ ê³µê°„ì´ ì»¤ì§ˆìˆ˜ë¡ ëª¨ë“  ìƒíƒœ-í–‰ë™ ìŒì„ ì¶©ë¶„íˆ íƒìƒ‰í•˜ê³  Q-ê°’ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë° í•„ìš”í•œ ì‹œê°„ì´ í¬ê²Œ ì¦ê°€í•©ë‹ˆë‹¤. ì´ëŠ” í•™ìŠµ ì†ë„ë¥¼ í˜„ì €íˆ ì €í•˜ì‹œí‚µë‹ˆë‹¤.\n","  - 3. íƒìƒ‰-í™œìš© ë”œë ˆë§ˆ : í° ìƒíƒœ ê³µê°„ì—ì„œëŠ” ëª¨ë“  ìƒíƒœë¥¼ ì¶©ë¶„íˆ íƒìƒ‰í•˜ê¸° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìµœì  ì •ì±…ì„ ì°¾ëŠ” ë° í•„ìš”í•œ íƒìƒ‰ê³¼ í•™ìŠµëœ ì •ì±…ì„ í™œìš©í•˜ëŠ” ê²ƒ ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ê¸°ê°€ ë”ìš± ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.\n","\n","## ì½”ë“œ ì„¤ëª…\n","\n","ì œê³µëœ ì½”ë“œëŠ” Q-Learningì„ êµ¬í˜„í•œ ì˜ˆì œì…ë‹ˆë‹¤. `Env` í´ë˜ìŠ¤ëŠ” ê·¸ë¦¬ë“œ ì›”ë“œ í™˜ê²½ì„, `QLearningAgent` í´ë˜ìŠ¤ëŠ” Q-Learning ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n","\n","### ì£¼ìš” í•¨ìˆ˜ ì„¤ëª…\n","\n","1. `Env` í´ë˜ìŠ¤:\n","   - `__init__`: í™˜ê²½ ì´ˆê¸°í™”\n","   - `step`: í–‰ë™ ìˆ˜í–‰ ë° ë‹¤ìŒ ìƒíƒœ, ë³´ìƒ ë°˜í™˜\n","   - `reset`: í™˜ê²½ ì´ˆê¸°í™”\n","\n","2. `QLearningAgent` í´ë˜ìŠ¤:\n","   - `learn`: Q-í•¨ìˆ˜ ì—…ë°ì´íŠ¸\n","   - `get_action`: Îµ-greedy ì •ì±…ì— ë”°ë¥¸ í–‰ë™ ì„ íƒ\n","\n","### ì½”ë“œ ì‹¤í–‰ ê³¼ì •\n","\n","1. í™˜ê²½ê³¼ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\n","2. ì—í”¼ì†Œë“œ ë°˜ë³µ:\n","   - ìƒíƒœ ì´ˆê¸°í™”\n","   - í–‰ë™ ì„ íƒ ë° ìˆ˜í–‰\n","   - Q-í•¨ìˆ˜ ì—…ë°ì´íŠ¸\n","   - ìƒˆë¡œìš´ ìƒíƒœë¡œ ì´ë™\n","   - Q-ê°’ ì¶œë ¥\n","3. 1000 ì—í”¼ì†Œë“œ ë™ì•ˆ ë°˜ë³µ\n","\n","ì´ ì½”ë“œë¥¼ í†µí•´ ì—ì´ì „íŠ¸ëŠ” ê·¸ë¦¬ë“œ ì›”ë“œì—ì„œ ì¥ì• ë¬¼ì„ í”¼í•´ ëª©í‘œì— ë„ë‹¬í•˜ëŠ” ìµœì  ê²½ë¡œë¥¼ í•™ìŠµí•©ë‹ˆë‹¤."],"metadata":{"id":"ZsmxIpJb7bXE"}},{"cell_type":"markdown","source":["* ì•„ë˜ ì½”ë“œëŠ” ì½”ë© í™˜ê²½ì´ ì•„ë‹Œ ë¡œì»¬ íŒŒì´ì¬ í™˜ê²½ì—ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”!\n","* ì½”ë“œ ì¶œì²˜ : https://github.com/rlcode/reinforcement-learning-kr"],"metadata":{"id":"clS6LSCn_kL3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_4ECiNi03ziV"},"outputs":[],"source":["# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n","import time  # ë”œë ˆì´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ ì‚¬ìš©\n","import numpy as np  # ë°°ì—´ ë° ìˆ˜í•™ì  ê³„ì‚°ì— ì‚¬ìš©\n","import tkinter as tk  # GUI í™˜ê²½ì„ êµ¬ì„±í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","from PIL import ImageTk, Image  # ì´ë¯¸ì§€ë¥¼ tkinterì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë³€í™˜\n","\n","# ëœë¤ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥ì„± ë³´ì¥)\n","np.random.seed(1)\n","\n","# tkinterì—ì„œ ì‚¬ìš©í•  ì´ë¯¸ì§€ ê°ì²´\n","PhotoImage = ImageTk.PhotoImage\n","\n","# ê·¸ë¦¬ë“œì›”ë“œ í¬ê¸° ì„¤ì •\n","UNIT = 100  # ê° ì…€ì˜ í¬ê¸° (í”½ì…€)\n","HEIGHT = 5  # ê·¸ë¦¬ë“œì›”ë“œì˜ ì„¸ë¡œ í¬ê¸° (ì…€ ë‹¨ìœ„)\n","WIDTH = 5  # ê·¸ë¦¬ë“œì›”ë“œì˜ ê°€ë¡œ í¬ê¸° (ì…€ ë‹¨ìœ„)\n","\n","\n","class Env(tk.Tk):\n","    def __init__(self):\n","        # tkinterì˜ Tk í´ë˜ìŠ¤ë¥¼ ì´ˆê¸°í™”\n","        super(Env, self).__init__()\n","        # í™˜ê²½ì—ì„œ ì‚¬ìš©í•  í–‰ë™ë“¤ (ìƒ, í•˜, ì¢Œ, ìš°)\n","        self.action_space = ['u', 'd', 'l', 'r']\n","        self.n_actions = len(self.action_space)  # í–‰ë™ì˜ ê°œìˆ˜\n","        self.title('Q Learning')  # ìœˆë„ìš° ì œëª©\n","        self.geometry('{0}x{1}'.format(HEIGHT * UNIT, HEIGHT * UNIT))  # ìœˆë„ìš° í¬ê¸°\n","        self.shapes = self.load_images()  # ì‚¬ìš©í•  ì´ë¯¸ì§€ ë¡œë“œ\n","        self.canvas = self._build_canvas()  # ìº”ë²„ìŠ¤ ì´ˆê¸°í™”\n","        self.texts = []  # ê·¸ë¦¬ë“œ ì•ˆì— í…ìŠ¤íŠ¸ í‘œì‹œë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n","\n","    def _build_canvas(self):\n","        # ìº”ë²„ìŠ¤ ìƒì„± (ê·¸ë¦¬ë“œ ë° ì´ë¯¸ì§€ ì¶”ê°€)\n","        canvas = tk.Canvas(self, bg='white',\n","                           height=HEIGHT * UNIT,\n","                           width=WIDTH * UNIT)\n","        # ì„¸ë¡œì„  ê·¸ë¦¬ê¸°\n","        for c in range(0, WIDTH * UNIT, UNIT):\n","            x0, y0, x1, y1 = c, 0, c, HEIGHT * UNIT\n","            canvas.create_line(x0, y0, x1, y1)\n","        # ê°€ë¡œì„  ê·¸ë¦¬ê¸°\n","        for r in range(0, HEIGHT * UNIT, UNIT):\n","            x0, y0, x1, y1 = 0, r, HEIGHT * UNIT, r\n","            canvas.create_line(x0, y0, x1, y1)\n","\n","        # ìº”ë²„ìŠ¤ì— ì´ë¯¸ì§€ ì¶”ê°€\n","        self.rectangle = canvas.create_image(50, 50, image=self.shapes[0])  # ë¹¨ê°„ ë„¤ëª¨ (ì—ì´ì „íŠ¸)\n","        self.triangle1 = canvas.create_image(250, 150, image=self.shapes[1])  # ì¥ì• ë¬¼1\n","        self.triangle2 = canvas.create_image(150, 250, image=self.shapes[1])  # ì¥ì• ë¬¼2\n","        self.circle = canvas.create_image(250, 250, image=self.shapes[2])  # ëª©í‘œ ì§€ì \n","\n","        canvas.pack()  # ìº”ë²„ìŠ¤ë¥¼ tkinter ìœˆë„ìš°ì— ì¶”ê°€\n","        return canvas\n","\n","    def load_images(self):\n","        # ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  í¬ê¸°ë¥¼ ì¡°ì •í•˜ì—¬ ë°˜í™˜\n","        rectangle = PhotoImage(\n","            Image.open(\"../img/rectangle.png\").resize((65, 65)))\n","        triangle = PhotoImage(\n","            Image.open(\"../img/triangle.png\").resize((65, 65)))\n","        circle = PhotoImage(\n","            Image.open(\"../img/circle.png\").resize((65, 65)))\n","\n","        return rectangle, triangle, circle  # ë¡œë“œëœ ì´ë¯¸ì§€ ë°˜í™˜\n","\n","    def text_value(self, row, col, contents, action, font='Helvetica', size=10,\n","                   style='normal', anchor=\"nw\"):\n","        # ê·¸ë¦¬ë“œ ì•ˆì— Q ê°’ í‘œì‹œ\n","        if action == 0:  # ìƒ\n","            origin_x, origin_y = 7, 42\n","        elif action == 1:  # í•˜\n","            origin_x, origin_y = 85, 42\n","        elif action == 2:  # ì¢Œ\n","            origin_x, origin_y = 42, 5\n","        else:  # ìš°\n","            origin_x, origin_y = 42, 77\n","\n","        # í…ìŠ¤íŠ¸ì˜ ì¢Œí‘œ ê³„ì‚°\n","        x, y = origin_y + (UNIT * col), origin_x + (UNIT * row)\n","        font = (font, str(size), style)\n","        text = self.canvas.create_text(x, y, fill=\"black\", text=contents,\n","                                       font=font, anchor=anchor)\n","        return self.texts.append(text)\n","\n","    def print_value_all(self, q_table):\n","        # í˜„ì¬ Q í…Œì´ë¸” ê°’ì„ ìº”ë²„ìŠ¤ì— í‘œì‹œ\n","        for i in self.texts:\n","            self.canvas.delete(i)\n","        self.texts.clear()  # ì´ì „ í…ìŠ¤íŠ¸ ì§€ìš°ê¸°\n","        for i in range(HEIGHT):\n","            for j in range(WIDTH):\n","                for action in range(0, 4):\n","                    state = [i, j]\n","                    if str(state) in q_table.keys():\n","                        temp = q_table[str(state)][action]\n","                        self.text_value(j, i, round(temp, 2), action)\n","\n","    def coords_to_state(self, coords):\n","        # ìº”ë²„ìŠ¤ ì¢Œí‘œë¥¼ ê·¸ë¦¬ë“œì›”ë“œì˜ ìƒíƒœë¡œ ë³€í™˜\n","        x = int((coords[0] - 50) / 100)\n","        y = int((coords[1] - 50) / 100)\n","        return [x, y]\n","\n","    def state_to_coords(self, state):\n","        # ê·¸ë¦¬ë“œì›”ë“œ ìƒíƒœë¥¼ ìº”ë²„ìŠ¤ ì¢Œí‘œë¡œ ë³€í™˜\n","        x = int(state[0] * 100 + 50)\n","        y = int(state[1] * 100 + 50)\n","        return [x, y]\n","\n","    def reset(self):\n","        # í™˜ê²½ì„ ì´ˆê¸° ìƒíƒœë¡œ ë¦¬ì…‹\n","        self.update()\n","        time.sleep(0.5)  # ë”œë ˆì´ ì¶”ê°€\n","        x, y = self.canvas.coords(self.rectangle)  # ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ì¢Œí‘œ\n","        self.canvas.move(self.rectangle, UNIT / 2 - x, UNIT / 2 - y)  # ì´ˆê¸° ìœ„ì¹˜ë¡œ ì´ë™\n","        self.render()  # í™˜ê²½ ì‹œê°í™”\n","        return self.coords_to_state(self.canvas.coords(self.rectangle))  # ì´ˆê¸° ìƒíƒœ ë°˜í™˜\n","\n","    def step(self, action):\n","        # ì£¼ì–´ì§„ í–‰ë™ì— ë”°ë¼ í™˜ê²½ì˜ ìƒíƒœë¥¼ ë³€í™”ì‹œí‚¤ê³  ë³´ìƒì„ ë°˜í™˜\n","        state = self.canvas.coords(self.rectangle)  # í˜„ì¬ ì—ì´ì „íŠ¸ ì¢Œí‘œ\n","        base_action = np.array([0, 0])  # ì´ë™ ë°©í–¥ ì´ˆê¸°í™”\n","        self.render()  # í™˜ê²½ ì‹œê°í™”\n","\n","        # í–‰ë™ì— ë”°ë¥¸ ì´ë™ ë°©í–¥ ê²°ì •\n","        if action == 0:  # ìƒ\n","            if state[1] > UNIT:\n","                base_action[1] -= UNIT\n","        elif action == 1:  # í•˜\n","            if state[1] < (HEIGHT - 1) * UNIT:\n","                base_action[1] += UNIT\n","        elif action == 2:  # ì¢Œ\n","            if state[0] > UNIT:\n","                base_action[0] -= UNIT\n","        elif action == 3:  # ìš°\n","            if state[0] < (WIDTH - 1) * UNIT:\n","                base_action[0] += UNIT\n","\n","        # ì—ì´ì „íŠ¸ ì´ë™\n","        self.canvas.move(self.rectangle, base_action[0], base_action[1])\n","        self.canvas.tag_raise(self.rectangle)  # ì—ì´ì „íŠ¸ë¥¼ ë§¨ ìœ„ë¡œ ë°°ì¹˜\n","        next_state = self.canvas.coords(self.rectangle)  # ë‹¤ìŒ ìƒíƒœ\n","\n","        # ë³´ìƒ í•¨ìˆ˜\n","        if next_state == self.canvas.coords(self.circle):  # ëª©í‘œ ë„ë‹¬\n","            reward = 100\n","            done = True\n","        elif next_state in [self.canvas.coords(self.triangle1),\n","                            self.canvas.coords(self.triangle2)]:  # ì¥ì• ë¬¼ ë„ë‹¬\n","            reward = -100\n","            done = True\n","        else:  # ì´ë™ë§Œ í•œ ê²½ìš°\n","            reward = 0\n","            done = False\n","\n","        next_state = self.coords_to_state(next_state)  # ì¢Œí‘œë¥¼ ìƒíƒœë¡œ ë³€í™˜\n","        return next_state, reward, done  # ë‹¤ìŒ ìƒíƒœ, ë³´ìƒ, ì¢…ë£Œ ì—¬ë¶€ ë°˜í™˜\n","\n","    def render(self):\n","        # í™˜ê²½ ì‹œê°í™” ë° ë”œë ˆì´ ì¶”ê°€\n","        time.sleep(0.03)\n","        self.update()\n"]},{"cell_type":"code","source":["import numpy as np\n","import random\n","from environment import Env  # ê·¸ë¦¬ë“œ ì›”ë“œ í™˜ê²½ì„ ì •ì˜í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ í´ë˜ìŠ¤\n","from collections import defaultdict  # ê¸°ë³¸ê°’ì´ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±ì— ì‚¬ìš©\n","\n","class QLearningAgent:\n","    def __init__(self, actions):\n","        # Q-Learning ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n","        # í–‰ë™(actions): [0, 1, 2, 3] ìˆœì„œëŒ€ë¡œ ìƒ, í•˜, ì¢Œ, ìš°ë¥¼ ì˜ë¯¸\n","        self.actions = actions  # ì—ì´ì „íŠ¸ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” í–‰ë™ ë¦¬ìŠ¤íŠ¸\n","        self.learning_rate = 0.01  # í•™ìŠµë¥  Î±: ìƒˆ ì •ë³´ ë°˜ì˜ ì •ë„\n","        self.discount_factor = 0.9  # í• ì¸ ê³„ìˆ˜ Î³: ë¯¸ë˜ ë³´ìƒì˜ ì¤‘ìš”ë„\n","        self.epsilon = 0.9  # íƒí—˜ í™•ë¥  Îµ: ë¬´ì‘ìœ„ í–‰ë™ ì„ íƒ ë¹„ìœ¨\n","        # Q í…Œì´ë¸” ì´ˆê¸°í™”: ìƒíƒœë³„ë¡œ [0.0, 0.0, 0.0, 0.0] ì´ˆê¸°ê°’ì„ ê°€ì§€ëŠ” ë”•ì…”ë„ˆë¦¬\n","        self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n","\n","    # <s, a, r, s'> ìƒ˜í”Œë¡œë¶€í„° Q-í•¨ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸\n","    def learn(self, state, action, reward, next_state):\n","        # í˜„ì¬ ìƒíƒœ(state)ì™€ í–‰ë™(action)ì— ëŒ€í•œ Q ê°’\n","        q_1 = self.q_table[state][action]\n","        # ë²¨ë§Œ ìµœì  ë°©ì •ì‹ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ëŒ€ìƒ Q ê°’ ê³„ì‚°\n","        # reward + Î³ * max(Q(s', a')): í˜„ì¬ ë³´ìƒê³¼ ë‹¤ìŒ ìƒíƒœì—ì„œì˜ ìµœëŒ€ Q ê°’\n","        q_2 = reward + self.discount_factor * max(self.q_table[next_state])\n","        # Q ê°’ ì—…ë°ì´íŠ¸: ê¸°ì¡´ Q ê°’ì— í•™ìŠµë¥ ì„ ê³±í•œ TD ì˜¤ì°¨ë¥¼ ë”í•¨\n","        self.q_table[state][action] += self.learning_rate * (q_2 - q_1)\n","\n","    # Q-í…Œì´ë¸” ê¸°ë°˜ì˜ Îµ-íƒìš• ì •ì±…ìœ¼ë¡œ í–‰ë™ ì„ íƒ\n","    def get_action(self, state):\n","        if np.random.rand() < self.epsilon:\n","            # íƒí—˜(Exploration): ë¬´ì‘ìœ„ í–‰ë™ ì„ íƒ\n","            action = np.random.choice(self.actions)\n","        else:\n","            # í™œìš©(Exploitation): Q-í…Œì´ë¸”ì—ì„œ ê°€ì¥ ë†’ì€ ê°’ì„ ê°€ì§„ í–‰ë™ ì„ íƒ\n","            state_action = self.q_table[state]\n","            action = self.arg_max(state_action)\n","        return action\n","\n","    @staticmethod\n","    def arg_max(state_action):\n","        # Q ê°’ì´ ìµœëŒ€ì¸ í–‰ë™ì„ ë°˜í™˜\n","        max_index_list = []  # ìµœëŒ€ Q ê°’ì„ ê°€ì§„ í–‰ë™ë“¤ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸\n","        max_value = state_action[0]  # ì²« ë²ˆì§¸ ê°’ì„ ì´ˆê¸° ìµœëŒ€ê°’ìœ¼ë¡œ ì„¤ì •\n","        for index, value in enumerate(state_action):\n","            if value > max_value:\n","                # ìƒˆë¡œìš´ ìµœëŒ€ê°’ ë°œê²¬ ì‹œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” í›„ ì¶”ê°€\n","                max_index_list.clear()\n","                max_value = value\n","                max_index_list.append(index)\n","            elif value == max_value:\n","                # ìµœëŒ€ê°’ê³¼ ê°™ì€ ê°’ì„ ê°€ì§„ í–‰ë™ ì¶”ê°€\n","                max_index_list.append(index)\n","        return random.choice(max_index_list)  # ìµœëŒ€ê°’ í–‰ë™ ì¤‘ ë¬´ì‘ìœ„ë¡œ ì„ íƒ\n","\n","if __name__ == \"__main__\":\n","    env = Env()  # ì‚¬ìš©ì ì •ì˜ í™˜ê²½ ì´ˆê¸°í™”\n","    agent = QLearningAgent(actions=list(range(env.n_actions)))  # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\n","\n","    for episode in range(1000):  # 1000ê°œì˜ ì—í”¼ì†Œë“œ ë™ì•ˆ í•™ìŠµ ë°˜ë³µ\n","        state = env.reset()  # í™˜ê²½ ì´ˆê¸°í™” ë° ì´ˆê¸° ìƒíƒœ ë°˜í™˜\n","\n","        while True:  # í•œ ì—í”¼ì†Œë“œ ë™ì•ˆ ë°˜ë³µ\n","            env.render()  # í™˜ê²½ ì‹œê°í™” (í˜„ì¬ ìƒíƒœ ì¶œë ¥)\n","\n","            # í˜„ì¬ ìƒíƒœ(state)ì— ë”°ë¥¸ í–‰ë™(action) ì„ íƒ\n","            action = agent.get_action(str(state))\n","            # í–‰ë™ ìˆ˜í–‰ í›„ ë‹¤ìŒ ìƒíƒœ(next_state), ë³´ìƒ(reward), ì¢…ë£Œ ì—¬ë¶€(done) ë°˜í™˜\n","            next_state, reward, done = env.step(action)\n","\n","            # Q-í•¨ìˆ˜ ì—…ë°ì´íŠ¸: <s, a, r, s'> ìƒ˜í”Œë¡œ í•™ìŠµ\n","            agent.learn(str(state), action, reward, str(next_state))\n","            state = next_state  # ìƒíƒœ ì—…ë°ì´íŠ¸\n","\n","            # ëª¨ë“  ìƒíƒœ-í–‰ë™ì— ëŒ€í•œ Q ê°’ì„ í™”ë©´ì— í‘œì‹œ\n","            env.print_value_all(agent.q_table)\n","\n","            if done:  # ì—í”¼ì†Œë“œ ì¢…ë£Œ ì¡°ê±´\n","                break\n"],"metadata":{"id":"YNcuFrNh_3Jg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ì‹¤ìŠµ ë¬¸ì œ 1: Ïµ-Decay ë¥¼ ì ìš©í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ğœ– ì´ ì¤„ì–´ë“¤ë„ë¡ ì„¤ì •í•˜ì„¸ìš”."],"metadata":{"id":"5_cj_kq5SEKI"},"execution_count":null,"outputs":[]}]}