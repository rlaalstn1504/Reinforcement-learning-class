{"cells":[{"cell_type":"markdown","source":["### 딥러닝과 강화학습의 융합\n","1. **강화학습(RL)**: 에이전트가 환경과 상호작용하며 최적의 행동을 학습하는 과정.\n","   - 핵심 요소:\n","     - **상태(State)**: 현재 환경의 상태.\n","     - **행동(Action)**: 에이전트가 취할 수 있는 행동.\n","     - **보상(Reward)**: 행동의 결과로 환경이 에이전트에 제공하는 피드백.\n","     - **정책(Policy)**: 상태에 따라 행동을 결정하는 함수.\n","   - 목표: 보상을 최대로 만드는 정책 학습.\n","\n","2. **딥러닝(DL)**: 심층 신경망을 사용하여 복잡한 패턴이나 함수를 모델링.\n","   - 강화학습의 비선형 함수 근사를 위해 딥러닝이 사용됨.\n","\n","3. **심층 강화학습(DRL)**: 딥러닝과 강화학습의 융합.\n","   - Q-값, 정책 함수 등을 심층 신경망으로 근사.\n","   - 복잡한 환경에서도 학습 가능."],"metadata":{"id":"BbpdpMP-Jiov"}},{"cell_type":"markdown","source":["### DQN (Deep Q-Network) 소개\n","- 전통적인 Q-Learning은 상태 공간이 클 경우 Q-테이블을 저장하기 어렵고, 일반화가 어려움.\n","- **DQN**은 심층 신경망(Deep Neural Network)을 사용하여 Q-값을 근사:\n","  - 입력: 상태(state).\n","  - 출력: 행동(action)에 대한 Q-값.\n","\n","#### 주요 특징\n","1. **경험 재생(Experience Replay)**:\n","   - 에이전트가 경험한 데이터를 저장하여 랜덤 샘플링으로 학습.\n","   - 데이터 간 상관성을 줄이고 학습 효율 향상.\n","\n","2. **타겟 네트워크(Target Network)**:\n","   - Q-값 업데이트 안정성을 위해 메인 네트워크와 별도로 고정된 타겟 네트워크 사용.\n","   - 일정 간격으로 타겟 네트워크를 메인 네트워크의 가중치로 갱신."],"metadata":{"id":"nmMA13RrJmLr"}},{"cell_type":"markdown","source":["## **1. Q-Learning 업데이트 수식**\n","\n","기존 Q-Learning에서는 다음과 같은 수식을 사용합니다:\n","\n","$$\n","Q(s, a) \\leftarrow Q(s, a) + \\alpha \\Big(r + \\gamma max_{a'} Q(s', a') - Q(s, a) $\\Big)\n","$$\n","\n","- **$Q(s, a)$**: 상태 $( s $)에서 행동 $( a $)를 했을 때의 Q-값 (예상 보상)\n","- **$r $**: 현재 행동 $( a $)를 통해 받은 보상\n","- **$\\gamma$**: 할인율 (미래 보상을 현재 가치로 반영할 비율)\n","- **$\\alpha$**: 학습률 (새로운 값과 기존 값의 반영 비율)\n","- **$\\max_{a'} Q(s', a') $**: 다음 상태 $( s' $)에서 가능한 행동 중 가장 큰 Q-값"],"metadata":{"id":"62zamTaaA4rv"}},{"cell_type":"markdown","source":["## **2. DQN의 업데이트 수식**\n","\n","DQN의 손실 함수는 \"현재 시점에서의 Q값\"과 \"미래의 기대 보상으로 계산된 목표 Q값\" 간의 차이를 줄이는 것을 목표로 합니다. 이를 통해 Q함수가 점점 더 정확하게 미래의 보상을 반영하게 되고, 에이전트가 최적의 행동을 학습할 수 있습니다.\n","\n","DQN은 심층 신경망(Deep Neural Network)을 사용하여 $Q\\$값을 근사합니다. 업데이트를 위해 다음 **손실 함수**(Loss Function)를 사용합니다:\n","\n","$$\n","\\text{Loss} = \\Big( r + \\gamma \\max_{a'} Q_{\\text{target}}(s', a') - Q_{\\text{main}}(s, a) \\Big)^2\n","$$\n","\n","- **$Q_{\\text{main}}(s, a)$**: 메인 네트워크에서 예측한 Q-값\n","- **$Q_{\\text{target}}(s', a')$**: 타겟 네트워크에서 계산한 Q-값 (고정된 값 사용)\n","- **$r$**: 현재 보상\n","- **$\\gamma \\max_{a'} Q_{\\text{target}}(s', a')$**: 미래 보상의 예상치\n","\n","이 손실 함수를 최소화하도록 메인 네트워크가 학습됩니다.\n"],"metadata":{"id":"LX26s2rpA4hB"}},{"cell_type":"markdown","source":["## **3. 경험 재생 (Experience Replay)**\n","\n","경험 재생은 DQN의 중요한 구성 요소 중 하나입니다. 이를 통해 신경망 학습의 안정성을 높입니다.\n","\n","### **개념 설명**:\n","- 에이전트는 환경과 상호작용하면서 경험을 만듭니다. 각 경험은 다음과 같은 형태로 저장됩니다:  \n","$(s, a, r, s', \\text{done})$\n","  - **$ s $**: 현재 상태\n","  - **$ a $**: 행동\n","  - **$ r $**: 보상\n","  - **$ s' $**: 다음 상태\n","  - **$\\text{done}$**: 에피소드 종료 여부 (True/False)\n","\n","- 이러한 경험을 모두 **메모리 버퍼(Replay Buffer)**순차적으로 저장됩니다. 학습 시, 이 버퍼에서 **랜덤 샘플링** 을 통해 데이터를 추출해 신경망을 학습시킵니다.\n","\n","### **왜 경험 재생이 필요한가?**  \n","1. **데이터 상관성 제거**:  \n","   에이전트가 연속된 데이터를 사용하면 매우 비슷한 상태-행동 쌍이 반복적으로 등장하여, 모델이 특정 패턴에 편향될 가능성을 높입니다. 랜덤 샘플링을 통해 이를 방지합니다.  \n","2. **데이터 재사용**:  \n","  - 경험 재생은 한 번의 경험을 여러 번 학습에 사용합니다.\n","이로 인해 새로운 데이터를 계속 생성하지 않아도 효율적으로 학습할 수 있습니다.\n","  -  이를 통해 더 적은 데이터로도 신경망을 효과적으로 학습시킬 수 있습니다.\n","\n","### **쉽게 비유하면**:\n","- 경험 재생은 과거의 학습 기록(노트)을 모아두고 복습하는 것과 같습니다.\n","- 즉, 에이전트가 과거 경험을 \"기록\"해두었다가 중요한 순간에 다시 꺼내 학습하는 방식입니다.\n","- 이를 통해 학습 과정에서 데이터가 부족하거나 연속된 데이터의 영향을 최소화할 수 있습니다."],"metadata":{"id":"slTnIlIDA4ek"}},{"cell_type":"markdown","source":["## **4. 타겟 네트워크 (Target Network)**\n","\n","타겟 네트워크는 DQN 학습의 **안정성**을 높이는 기술입니다.\n","\n","### **동작 원리**:\n","- **메인 네트워크**:\n","  1. 에이전트가 현재 상태에서 최적의 행동을 선택하도록 학습합니다.\n","  2. Q-값을 계산해 행동의 가치를 예측합니다.\n","  \n","- **타겟 네트워크**:\n","  1. 메인 네트워크의 가중치를 일정 주기마다 복사해 고정된 상태로 유지합니다.\n","  2. 학습 중 목표값(Target Q-value)을 계산하는 데 사용됩니다.\n","\n","### **왜 타겟 네트워크가 필요한가?**\n","- DQN에서는 목표 Q-값(Target Q-value)을 예측하기 위해 메인 네트워크의 Q-값을 사용합니다. 하지만 이 값이 학습 중 계속 변한다면 목표값 자체가 흔들리며 학습이 불안정해질 수 있습니다.\n","- **타겟 네트워크**는 일정 기간 동안 고정된 값을 제공하여 목표 Q-값을 안정적으로 유지하도록 돕습니다.\n","- 일정 주기마다 타겟 네트워크를 메인 네트워크로 업데이트하면서 최신 정보를 반영합니다.\n","\n","### **쉽게 비유하면**:\n","타겟 네트워크는 **참고서**와 같습니다. 참고서는 일정 시간 동안 바뀌지 않으므로 학습 목표가 흔들리지 않습니다. 대신 시간이 지나면 최신 정보를 반영해 갱신됩니다."],"metadata":{"id":"RjXyGs_qBFT3"}},{"cell_type":"markdown","metadata":{"id":"38pOBp53w6ah"},"source":["## **5. 전체 구조 정리**\n","\n","DQN의 학습 과정은 다음과 같습니다:\n","1. **환경과 상호작용**하며 경험$( (s, a, r, s',\\text{done})$)를 저장.\n","2. 메모리 버퍼에서 **랜덤 샘플링**을 통해 학습 데이터를 추출.\n","3. 메인 네트워크에서 현재 상태의 Q-값$( Q_{\\text{main}}(s, a)$)를 예측.\n","4. 타겟 네트워크에서 목표 Q-값$(r +\\gamma \\max_{a'} Q_{\\text{target}}(s', a'))$를 계산.\n","5. 손실 함수(Loss)를 계산하고 메인 네트워크를 **업데이트**.\n","6. 일정 주기마다 타겟 네트워크를 메인 네트워크로 **동기화**.\n","\n","<img src=\"https://blog.kakaocdn.net/dn/cw2t8w/btrDU3Srd1K/Ds7UlI3vY9qEhYqNtXSqi0/img.jpg\" width=\"500\">\n"]},{"cell_type":"markdown","metadata":{"id":"IVZyTI_oxEsY"},"source":["## DQN 실습\n","\n","간단한 OpenAI Gym 환경에서 DQN 모델을 구현하여 학습하는 과정을 실습합니다.\n","\n","- 환경: `CartPole-v1`.\n","- 목표: 막대가 쓰러지지 않고 균형을 유지하도록 에이전트를 학습.\n","- 주요 구성 요소:\n","  1. 경험 재생(Experience Replay)을 위한 메모리 버퍼.\n","  2. 메인 네트워크와 타겟 네트워크.\n","  3. DQN 학습 루프.\n","- 종료 조건 :\n","    1. 막대의 각도가 일정 한계를 벗어나는 경우\n","    2. 정해진 일정 시간을 초과하는 경우"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyqDYVnuynX_","collapsed":true},"outputs":[],"source":["# 필요한 라이브러리 임포트\n","import numpy as np  # 수학적 계산 및 배열 처리\n","import tensorflow as tf  # 딥러닝 프레임워크\n","from tensorflow.keras import Sequential  # 순차 모델\n","from tensorflow.keras.layers import Dense  # 신경망 층\n","from collections import deque  # 경험 재생 버퍼 구현을 위한 큐\n","import gym  # 강화학습 환경 제공 라이브러리\n","\n","# CartPole-v1 환경을 생성하고 초기화\n","# render_mode=\"human\"을 통해 환경 시각화\n","env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n","state = env.reset()  # 초기 상태 가져오기\n","\n","# 상태 공간의 크기와 행동 공간의 크기 정의\n","state_size = env.observation_space.shape[0]  # 상태의 차원 (카트의 위치, 속도, 막대의 각도, 각속도)\n","action_size = env.action_space.n  # 가능한 행동의 수 (왼쪽, 오른쪽)\n","\n","# 경험 재생(Experience Replay)을 위한 버퍼 클래스\n","class ReplayBuffer:\n","    def __init__(self, max_size=50000):\n","        # 버퍼를 deque로 생성 (최대 크기 50000)\n","        self.buffer = deque(maxlen=max_size)\n","\n","    def add(self, experience):\n","        # 새로운 경험 (state, action, reward, next_state, done)을 버퍼에 추가\n","        self.buffer.append(experience)\n","\n","    def sample(self, batch_size):\n","        # 버퍼에서 무작위로 batch_size개의 샘플을 추출\n","        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n","        return [self.buffer[idx] for idx in indices]\n","\n","    def size(self):\n","        # 현재 버퍼의 크기를 반환\n","        return len(self.buffer)\n","\n","# Q값을 예측할 신경망 모델을 생성하는 함수\n","def build_model():\n","    # 순차 모델 생성\n","    model = Sequential([\n","        Dense(24, input_dim=state_size, activation='relu'),  # 첫 번째 은닉층 (입력: 상태 크기)\n","        Dense(24, activation='relu'),  # 두 번째 은닉층\n","        Dense(action_size, activation='linear')  # 출력층 (출력: 각 행동의 Q값)\n","    ])\n","    # 모델 컴파일 (Adam 옵티마이저, 손실 함수: MSE)\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n","    return model\n","\n","# DQN 에이전트 클래스\n","class DQNAgent:\n","    def __init__(self):\n","        # 주 신경망 (Main Network) 생성\n","        self.main_model = build_model()\n","        # 타겟 신경망 (Target Network) 생성\n","        self.target_model = build_model()\n","        # 타겟 신경망의 가중치를 주 신경망과 동일하게 초기화\n","        self.target_model.set_weights(self.main_model.get_weights())\n","        # 경험 재생 버퍼 초기화\n","        self.replay_buffer = ReplayBuffer()\n","        # 하이퍼파라미터 설정\n","        self.gamma = 0.99  # 할인 계수 (미래 보상의 중요도)\n","        self.epsilon = 1.0  # 탐험률 초기값\n","        self.epsilon_decay = 0.995  # 탐험률 감소 비율\n","        self.epsilon_min = 0.01  # 최소 탐험률\n","        self.batch_size = 64  # 학습 배치 크기\n","\n","    def update_target_network(self):\n","        # 타겟 신경망의 가중치를 주 신경망의 가중치로 업데이트\n","        self.target_model.set_weights(self.main_model.get_weights())\n","\n","    def select_action(self, state):\n","        # 입실론-그리디 정책에 따라 행동 선택\n","        if np.random.rand() <= self.epsilon:\n","            # 무작위 행동 선택 (탐험)\n","            return env.action_space.sample()\n","        # 주 신경망을 통해 Q값 예측\n","        q_values = self.main_model.predict(state)\n","        # 가장 큰 Q값을 가진 행동 선택 (활용)\n","        return np.argmax(q_values[0])\n","\n","    def train(self):\n","        # 경험 재생 버퍼에서 배치를 샘플링하여 학습\n","        if self.replay_buffer.size() < self.batch_size:\n","            return  # 버퍼 크기가 배치 크기보다 작으면 학습하지 않음\n","\n","        # 배치 샘플링\n","        batch = self.replay_buffer.sample(self.batch_size)\n","        states, actions, rewards, next_states, dones = zip(*batch)\n","        states = np.array(states).squeeze(axis=1)  # 현재 상태\n","        next_states = np.array(next_states).squeeze(axis=1)  # 다음 상태\n","\n","        # 현재 상태에 대한 Q값 예측\n","        target_qs = self.main_model.predict(states)\n","        # 다음 상태에 대한 Q값 예측 (타겟 네트워크 사용)\n","        next_qs = self.target_model.predict(next_states)\n","\n","        # Q-Learning 업데이트 규칙 적용\n","        for i in range(self.batch_size):\n","            if dones[i]:  # 종료 상태에서는 보상만 반영\n","                target_qs[i][actions[i]] = rewards[i]\n","            else:  # 비종료 상태에서는 보상 + 할인된 미래 보상 반영\n","                target_qs[i][actions[i]] = rewards[i] + self.gamma * np.max(next_qs[i])\n","\n","        # 주 신경망 학습\n","        self.main_model.fit(states, target_qs, epochs=1, verbose=0, batch_size=32)\n","\n","# DQN 에이전트 생성\n","agent = DQNAgent()\n","episodes = 500  # 학습할 에피소드 수\n","\n","# 학습 루프\n","for episode in range(episodes):\n","    state = env.reset()  # 환경 초기화 및 상태 가져오기\n","    state = state[0] if isinstance(state, tuple) else state  # 상태가 튜플이면 첫 번째 요소 사용\n","    state = np.reshape(state, [1, state_size])  # 상태를 2D 배열로 변환\n","    total_reward = 0\n","    done = False\n","\n","    while not done:\n","        # 행동 선택\n","        action = agent.select_action(state)\n","\n","        # 환경에서 한 스텝 진행\n","        step_result = env.step(action)\n","        if len(step_result) == 4:  # Gym 반환값 처리\n","            next_state, reward, done, info = step_result\n","        elif len(step_result) == 5:  # 일부 버전에서 반환값 추가 처리\n","            next_state, reward, done, truncated, info = step_result\n","            done = done or truncated  # truncated를 종료 조건으로 처리\n","        else:\n","            raise ValueError(f\"Unexpected step result length: {len(step_result)}\")\n","\n","        next_state = next_state[0] if isinstance(next_state, tuple) else next_state\n","        next_state = np.reshape(next_state, [1, state_size])  # 다음 상태 변환\n","\n","        # 경험을 리플레이 버퍼에 저장\n","        agent.replay_buffer.add((state, action, reward, next_state, done))\n","\n","        state = next_state  # 상태 업데이트\n","        total_reward += reward  # 총 보상 업데이트\n","\n","        # 에이전트 학습\n","        agent.train()\n","\n","    # 10 에피소드마다 타겟 네트워크 업데이트\n","    if episode % 10 == 0:\n","        agent.update_target_network()\n","\n","    # 탐험률 감소\n","    if agent.epsilon > agent.epsilon_min:\n","        agent.epsilon *= agent.epsilon_decay\n","\n","    # 에피소드 정보 출력\n","    if episode % 10 == 0:\n","        print(f\"Episode: {episode}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.2f}\")\n","\n","# 환경 종료\n","env.close()"]},{"cell_type":"code","source":["import os\n","from gym.wrappers import RecordVideo\n","\n","# 비디오 저장 경로 설정\n","video_save_path = \"./cartpole_videos\"\n","os.makedirs(video_save_path, exist_ok=True)\n","\n","# CartPole 환경을 생성하고 비디오 저장 설정\n","env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")  # 비디오 저장용 환경 생성\n","env = RecordVideo(env, video_save_path, episode_trigger=lambda x: True)  # 모든 에피소드 비디오 저장\n","\n","def play_and_record(agent, env, episodes=5):\n","    \"\"\"\n","    학습된 에이전트가 환경을 플레이하며 비디오를 저장하는 함수.\n","\n","    Args:\n","        agent: 학습된 DQN 에이전트.\n","        env: 비디오를 기록할 Gym 환경.\n","        episodes: 에이전트가 플레이할 에피소드 수.\n","    \"\"\"\n","    for episode in range(episodes):\n","        state = env.reset()\n","        state = state[0] if isinstance(state, tuple) else state  # 상태가 튜플이면 첫 번째 요소 사용\n","        state = np.reshape(state, [1, state_size])  # 상태를 2D 배열로 변환\n","        total_reward = 0\n","        done = False\n","\n","        while not done:\n","            # 학습된 네트워크로 행동 선택 (탐험 없이 활용만 수행)\n","            q_values = agent.main_model.predict(state)\n","            action = np.argmax(q_values[0])  # 가장 높은 Q값을 가진 행동 선택\n","\n","            # 환경에서 한 스텝 진행\n","            step_result = env.step(action)\n","            if len(step_result) == 4:  # Gym 반환값 처리\n","                next_state, reward, done, info = step_result\n","            elif len(step_result) == 5:  # 일부 버전에서 반환값 추가 처리\n","                next_state, reward, done, truncated, info = step_result\n","                done = done or truncated  # truncated를 종료 조건으로 처리\n","            else:\n","                raise ValueError(f\"Unexpected step result length: {len(step_result)}\")\n","\n","            next_state = next_state[0] if isinstance(next_state, tuple) else next_state\n","            next_state = np.reshape(next_state, [1, state_size])  # 다음 상태 변환\n","\n","            state = next_state  # 상태 업데이트\n","            total_reward += reward  # 총 보상 업데이트\n","\n","        print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")\n","\n","# 학습된 에이전트로 플레이하며 비디오 저장\n","play_and_record(agent, env, episodes=5)\n","\n","# 비디오 저장 완료 후 환경 종료\n","env.close()\n","\n","print(f\"비디오가 '{video_save_path}'에 저장되었습니다.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvnqXSq6cbwN","executionInfo":{"status":"ok","timestamp":1736081079622,"user_tz":-540,"elapsed":2811,"user":{"displayName":"김민수","userId":"14499279899039145671"}},"outputId":"bd9b9118-ddee-4a10-82d5-f8f3084001a1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Episode: 5, Total Reward: 177.0\n","비디오가 './cartpole_videos'에 저장되었습니다.\n"]}]},{"cell_type":"code","source":["from IPython.display import HTML\n","import base64\n","\n","def display_video(video_path):\n","    \"\"\"저장된 비디오를 Jupyter Notebook에서 재생\"\"\"\n","    with open(video_path, \"rb\") as video_file:\n","        video_data = video_file.read()\n","    encoded_video = base64.b64encode(video_data).decode(\"utf-8\")\n","    return HTML(f\"\"\"\n","        <video width=\"640\" height=\"480\" controls>\n","            <source src=\"data:video/mp4;base64,{encoded_video}\" type=\"video/mp4\">\n","        </video>\n","    \"\"\")\n","\n","# 비디오 파일 경로\n","video_file_path = f\"{video_save_path}/rl-video-episode-4.mp4\"\n","display_video(video_file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"xC8GXTprfnR0","executionInfo":{"status":"ok","timestamp":1736081208858,"user_tz":-540,"elapsed":368,"user":{"displayName":"김민수","userId":"14499279899039145671"}},"outputId":"c60d5d25-1eb9-4a4e-fe99-c0fa4fd8faf4"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","        <video width=\"640\" height=\"480\" controls>\n","            <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n","        </video>\n","    "]},"metadata":{},"execution_count":7}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyN39+gPlToTZSxd0ZOczt45"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}